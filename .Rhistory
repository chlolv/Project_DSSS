library(caret)  # confusion matrix
library(party)  # conditional inference random forests and trees
library(partykit)  # conditional inference trees
library(pROC)  # ROC curves and AUC
library(measures)  # performance measures
library(varImp)  # variable importance
library(permimp)  # conditional variable importance
library(pdp)  # partial dependence
library(vip)  # measure of interactions
library(moreparty)  # surrogate trees, accumulated local effects, etc.
library(RColorBrewer)  # color palettes
library(GDAtools)  # bivariate analysis
library(gridExtra)  # arrange multiple ggplots
library(ggpubr) # plot density
library(robumeta) # calculate group.mean
library(jtools)  # resultats de regressions et graphiques de coefficients
library(car)  # pour les diagnostics ('outlierTest')
library(gam)  # modèle additif généralisé
library(glmnet)  # Lasso, ridge, elastic net
library(plotmo)  # graphiques de dependances partielles (pour GAM et regressions regularisees)
library("kableExtra") # Mise en page des tableaux
# library(stargazer) # Mise en page des output des régressions
perfs_classif <- function(pred,actual) {
t <- table(predicted=factor(as.numeric(pred>0.5),levels=c(0,1)),actual)
acc <- sum(diag(t))/sum(t)
tpr <- t[2,2]/sum(t[,2])
tnr <- t[1,1]/sum(t[,1])
bac <- (tpr+tnr)/2
auc <- pROC::auc(actual,pred, quite=TRUE)
res <- c(auc,acc,tpr,tnr,bac)
res <- round(res,3)
names(res) <- c('auc','acc','tpr','tnr','bac')
return(res)
}
set.seed(1678)
pima_str <- pima
View(pima)
summary(pima)
sum(is.na(pima)/(nrow(pima)*ncol(pima))*100)
pima <- na.omit(pima)
# Recodage variables
pima$diabetes <- ifelse(pima$diabetes=="pos",1,0)
with(pima, table(diabetes,pregnant)) %>% prop.table(2) %>% `*`(100) %>% round(1)
ba <- BivariateAssoc(pima$diabetes, pima[,-9])
ba$YX
kbl(ba$YX[1:7,1:5]) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
ba$XX
kbl(ba$XX[1:7,c(1,2,4,5)]) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
# Estimation du modele
logit <- glm(diabetes~.,pima,family='binomial')
summ(logit)
# stargazer(logit, type = "html",  out = "basis_model.html", title = "Basis model")
pred <- predict(logit, type="response", newdata=pima)
perfs_classif(pred,pima$diabetes)
pred <- predict(logit, type="response", newdata=pima)
perfs_classif(pred,pima$diabetes)
rm(list=objects())
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(rmdformats)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=TRUE,
prompt=FALSE,
tidy=FALSE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=75)
# Chargement des packages utiles
library(tidyverse)  # data management
library(magrittr)  # aliases
library(caret)  # confusion matrix
library(party)  # conditional inference random forests and trees
library(partykit)  # conditional inference trees
library(pROC)  # ROC curves and AUC
library(measures)  # performance measures
library(varImp)  # variable importance
library(permimp)  # conditional variable importance
library(pdp)  # partial dependence
library(vip)  # measure of interactions
library(moreparty)  # surrogate trees, accumulated local effects, etc.
library(RColorBrewer)  # color palettes
library(GDAtools)  # bivariate analysis
library(gridExtra)  # arrange multiple ggplots
library(ggpubr) # plot density
library(robumeta) # calculate group.mean
library(jtools)  # resultats de regressions et graphiques de coefficients
library(car)  # pour les diagnostics ('outlierTest')
library(gam)  # modèle additif généralisé
library(glmnet)  # Lasso, ridge, elastic net
library(plotmo)  # graphiques de dependances partielles (pour GAM et regressions regularisees)
library("kableExtra") # Mise en page des tableaux
# library(stargazer) # Mise en page des output des régressions
perfs_classif <- function(pred,actual) {
t <- table(predicted=factor(as.numeric(pred>0.5),levels=c(0,1)),actual)
acc <- sum(diag(t))/sum(t)
tpr <- t[2,2]/sum(t[,2])
tnr <- t[1,1]/sum(t[,1])
bac <- (tpr+tnr)/2
auc <- pROC::auc(actual,pred, quite=TRUE)
res <- c(auc,acc,tpr,tnr,bac)
res <- round(res,3)
names(res) <- c('auc','acc','tpr','tnr','bac')
return(res)
}
set.seed(1678)
pima_str <- pima
View(pima)
summary(pima)
sum(is.na(pima)/(nrow(pima)*ncol(pima))*100)
pima <- na.omit(pima)
# Recodage variables
pima$diabetes <- ifelse(pima$diabetes=="pos",1,0)
with(pima, table(diabetes,pregnant)) %>% prop.table(2) %>% `*`(100) %>% round(1)
ba <- BivariateAssoc(pima$diabetes, pima[,-9])
ba$YX
kbl(ba$YX[1:7,1:5]) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
ba$XX
kbl(ba$XX[1:7,c(1,2,4,5)]) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
# Estimation du modele
logit <- glm(diabetes~.,pima,family='binomial')
summ(logit)
pred <- predict(logit, type="response", newdata=pima)
perfs_classif(pred,pima$diabetes)
(out <- outlierTest(logit))  # Bonferroni p-value for most extreme obs
# Influential Observations
# Cook's D plot
# identify D values > 4/(n-k-1)
cutoff <- 4/((nrow(logit$model)-length(logit$coefficients)-2))
plot(logit, which=4, cook.levels=cutoff)
# Regression sans les influential
infl <- c(229,460,488)
logit.infl <- glm(diabetes~., data=pima[-infl,], family='binomial')
summ(logit.infl)
vif(logit) # variance inflation factors
gam <- gam(diabetes ~ ., data=pima, family=binomial)
summary.glm(gam)
plotmo(gam, pmethod='partdep')
param = 0.5
# 1 -> LASSO
# 0 -> RIDGE
# 0.5 -> ELASTIC NET
# Estimation du modele
x_train <- model.matrix( ~ ., pima[,-9])[,-1]
cv.en <- cv.glmnet(x=x_train, y=pima[,9], family = "binomial", alpha=param, type.measure="deviance")
coef(cv.en, s='lambda.1se')
coef(cv.en, s='lambda.min')
x_train <- model.matrix( ~ ., pima[,-9])[,-1]
en.1se <- glmnet(x=x_train, y=pima[,9], family = "binomial", alpha=param, type.measure="deviance", lambda=cv.en$lambda.1se)
plotmo(en.1se, pmethod='partdep')
pred <- predict(cv.en,newx=x_train,type="response", s="lambda.min") %>% as.numeric
perfs_classif(pred,pima$diabetes)
arbre <- partykit::ctree(diabetes~., data=pima_str, control=partykit::ctree_control(minbucket=30, maxsurrogate=Inf, maxdepth=3))
print(arbre)
plot(arbre)
gamtabs(gam, caption='GAM')
library(itsadug)
gamtabs(gam, caption='GAM')
rm(list=objects())
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(rmdformats)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=TRUE,
prompt=FALSE,
tidy=FALSE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=75)
# Chargement des packages utiles
library(tidyverse)  # data management
library(magrittr)  # aliases
library(caret)  # confusion matrix
library(party)  # conditional inference random forests and trees
library(partykit)  # conditional inference trees
library(pROC)  # ROC curves and AUC
library(measures)  # performance measures
library(varImp)  # variable importance
library(permimp)  # conditional variable importance
library(pdp)  # partial dependence
library(vip)  # measure of interactions
library(moreparty)  # surrogate trees, accumulated local effects, etc.
library(RColorBrewer)  # color palettes
library(GDAtools)  # bivariate analysis
library(gridExtra)  # arrange multiple ggplots
library(ggpubr) # plot density
library(robumeta) # calculate group.mean
library(jtools)  # resultats de regressions et graphiques de coefficients
library(car)  # pour les diagnostics ('outlierTest')
library(gam)  # modèle additif généralisé
library(glmnet)  # Lasso, ridge, elastic net
library(plotmo)  # graphiques de dependances partielles (pour GAM et regressions regularisees)
library("kableExtra") # Mise en page des tableaux
# library(stargazer) # Mise en page des output des régressions
perfs_classif <- function(pred,actual) {
t <- table(predicted=factor(as.numeric(pred>0.5),levels=c(0,1)),actual)
acc <- sum(diag(t))/sum(t)
tpr <- t[2,2]/sum(t[,2])
tnr <- t[1,1]/sum(t[,1])
bac <- (tpr+tnr)/2
auc <- pROC::auc(actual,pred, quite=TRUE)
res <- c(auc,acc,tpr,tnr,bac)
res <- round(res,3)
names(res) <- c('auc','acc','tpr','tnr','bac')
return(res)
}
set.seed(1678)
pima_str <- pima
# View(pima)
summary(pima)
sum(is.na(pima)/(nrow(pima)*ncol(pima))*100)
pima <- na.omit(pima)
# Recodage variables
pima$diabetes <- ifelse(pima$diabetes=="pos",1,0)
with(pima, table(diabetes,pregnant)) %>% prop.table(2) %>% `*`(100) %>% round(1)
ba <- BivariateAssoc(pima$diabetes, pima[,-9])
ba$YX
kbl(ba$YX[1:7,1:5]) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
ba$XX
kbl(ba$XX[1:7,c(1,2,4,5)]) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
# Estimation du modele
logit <- glm(diabetes~.,pima,family='binomial')
summ(logit)
# stargazer(logit, type = "html",  out = "basis_model.html", title = "Basis model")
pred <- predict(logit, type="response", newdata=pima)
perfs_classif(pred,pima$diabetes)
(out <- outlierTest(logit))  # Bonferroni p-value for most extreme obs
# Influential Observations
# Cook's D plot
# identify D values > 4/(n-k-1)
cutoff <- 4/((nrow(logit$model)-length(logit$coefficients)-2))
plot(logit, which=4, cook.levels=cutoff)
# Regression sans les influential
infl <- c(229,460,488)
logit.infl <- glm(diabetes~., data=pima[-infl,], family='binomial')
summ(logit.infl)
vif(logit) # variance inflation factors
gam <- gam(diabetes ~ ., data=pima, family=binomial)
summary.glm(gam)
plotmo(gam, pmethod='partdep')
param = 0.5
# 1 -> LASSO
# 0 -> RIDGE
# 0.5 -> ELASTIC NET
# Estimation du modele
x_train <- model.matrix( ~ ., pima[,-9])[,-1]
cv.en <- cv.glmnet(x=x_train, y=pima[,9], family = "binomial", alpha=param, type.measure="deviance")
coef(cv.en, s='lambda.1se')
coef(cv.en, s='lambda.min')
x_train <- model.matrix( ~ ., pima[,-9])[,-1]
en.1se <- glmnet(x=x_train, y=pima[,9], family = "binomial", alpha=param, type.measure="deviance", lambda=cv.en$lambda.1se)
plotmo(en.1se, pmethod='partdep')
pred <- predict(cv.en,newx=x_train,type="response", s="lambda.min") %>% as.numeric
perfs_classif(pred,pima$diabetes)
arbre <- partykit::ctree(diabetes~., data=pima_str, control=partykit::ctree_control(minbucket=30, maxsurrogate=Inf, maxdepth=3))
print(arbre)
plot(arbre)
nodeapply(as.simpleparty(arbre), ids = nodeids(arbre, terminal = TRUE), FUN = function(x) round(prop.table(info_node(x)$distribution),3))
plot(arbre, inner_panel=node_inner(arbre,id=FALSE,pval=FALSE), terminal_panel=node_barplot(arbre,id=FALSE), gp=gpar(cex=0.6), ep_args=list(justmin=15))
pred_arbre <- predict(arbre, type='prob')[,'pos']
auc_arbre <- AUC(pred_arbre, pima_str$diabetes, positive='pos')
auc_arbre %>% round(3)
ifelse(pred_arbre > .5, "pos", "neg") %>%
factor %>%
caret::confusionMatrix(pima_str$diabetes, positive='pos')
GetSplitStats(arbre)
foret <- party::cforest(diabetes~., data=pima_str, controls=party::cforest_unbiased(mtry=2,ntree=500))
pred_foret <- predict(foret, type='prob') %>%
do.call('rbind.data.frame',.) %>%
select(2) %>%
unlist
auc_foret <- AUC(pred_foret, pima_str$diabetes, positive='pos')
auc_foret %>% round(3)
pred_oob <- predict(foret, type='prob', OOB=TRUE) %>%
do.call('rbind.data.frame',.) %>%
select(2) %>%
unlist
auc_oob <- AUC(pred_oob, pima_str$diabetes, positive='pos')
auc_oob %>% round(3)
surro <- SurrogateTree(foret, maxdepth=3)
surro$r.squared %>% round(3)
plot(surro$tree, inner_panel=node_inner(surro$tree,id=FALSE,pval=FALSE), terminal_panel=node_boxplot(surro$tree,id=FALSE), gp=gpar(cex=0.6), ep_args=list(justmin=15))
library(doParallel)
registerDoParallel(cores=2)
importance <- fastvarImpAUC(foret)
stopImplicitCluster()
importance %>% round(3)
ggVarImp(importance)
imp1 <- party::cforest(diabetes~., data=pima_str, controls=party::cforest_unbiased(stump=TRUE,mtry=2,ntree=500)) %>% varImpAUC %>% multiply_by(-1)  %>% round(3)
imp2 <- party::cforest(diabetes~., data=pima_str, controls=party::cforest_unbiased(mtry=1,ntree=500)) %>% varImpAUC %>% multiply_by(-1)  %>% round(3)
imp3 <- party::cforest(diabetes~., data=pima_str, controls=party::cforest_unbiased(mtry=4,ntree=500)) %>% varImpAUC %>% multiply_by(-1) %>% round(3)
imp4 <- permimp(foret)$values
grid.arrange(ggVarImp(imp1, main="no interaction"),
ggVarImp(imp2, main="mtry=1"),
ggVarImp(imp3, main="mtry=4"),
ggVarImp(imp4, main="conditional imp"), ncol=3)
# library(doParallel)
# registerDoParallel(cores=2)
# pdep <- GetPartialData(foret, which.class=2, probs=1:19/20, prob=TRUE)
# stopImplicitCluster()
pdep <- readRDS("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MiQS\\pdep.rds")
# unique(pdep)
# saveRDS(pdep, file = "C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MiQS\\pdep.rds")
ggForestEffects(pdep[!duplicated(pdep$cat),], vline=mean(unique(pred_foret)), xlab="Probability of survival") +
xlim(c(0,1))
ale <- GetAleData(foret)
ale
ale %>% mutate(value=round(value,3))
ggForestEffects(ale[!duplicated(ale$cat),])
featsel <- FeatureSelection(pima$diabetes, pima[,-9], method="RFE", positive="Yes")
featsel <- FeatureSelection(pima_str$diabetes, pima_str[,-9], method="RFE", positive="pos")
featsel$selection.0se
featsel$selection.1se
df = readRDS('‪C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\base_tweet_tot_2022-02-21)
''
'
df = readRDS('‪C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\base_tweet_tot_2022-02-21')
df <- readRDS('‪C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\base_tweet_tot_2022-02-21')
library(base)
df <- readRDS(r'‪C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\base_tweet_tot_2022-02-21')
df <- readRDS('‪C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\base_tweet_tot_2022-02-21')
df = readRDS("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\base_tweet_tot_2022-02-21")
names(df)
unique(df$type)
data <- df %>% filter(type="tweet")
data <- df %>% filter(type="tweet")
library("plyr")
library("dplyr")
library("data.table")
library("tidyverse")
data <- df %>% filter(type="tweet")
data <- df %>% filter(type == "tweet")
names(data)
unique(data$lang)
unique(data$entities)
rem <- c("entities","public_metrics","referenced_tweets","attachements",
"geo","withheld")
data <- select(data,-rem)
rem <- c("entities","public_metrics","referenced_tweets","attachments",
"geo","withheld")
data <- select(data,-rem)
data <- select(data,-c("entities","public_metrics","referenced_tweets","attachments",
"geo","withheld"))
)
''
""
"
"edzdzd"
)))
)
data <- select(data,-c("entities","public_metrics","referenced_tweets",
"attachments",
"geo","withheld"))
View(df)
names(data)
length(rem)
View(data)
del <- c("conversation_id","id.x","author.id","in_reply_to_user_id","id_twi",
"type","pre.nom","id.y","nom_de_famille","prenom","sites_web","url_an",
"id_an","slug","url_nosdeputes","url_nosdeputes_api","age_group")
data <- select(data,-del)
names(data)
del <- c("conversation_id","id.x","author_id","in_reply_to_user_id","id_twi",
"type","pre.nom","id.y","nom_de_famille","prenom","sites_web","url_an",
"id_an","slug","url_nosdeputes","url_nosdeputes_api","age_group")
data <- select(data,-del)
names(data)
write.csv2(data, "C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv")
unique(data$possibly_sensitive)
unique(data$source)
unique(data$twitter.x)
unique(data$twitter.y)
which(data$twitter.x != data$twitter.y)
names(data)
unique(data$cabcollab)
data <- select(data,-c("source","twitter.y"))
#-----------------------------------------------------#
library("plyr")
library("dplyr")
library("data.table")
library("tidyverse")
data <- read.csv2("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv
")
data <- read.csv2("C:\\Users\\HP\\Do
")"
")
data <- read.csv2("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv")
View(data)
names(data)
data <- select(data,-c("clustRFSP","clustVEP"))
names(data)
write.csv2(data,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv")
write.csv2(data,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv",
encoding = "utf-8")
write.csv2(data,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv",
fileEncoding = "UTF-8")
names(data)
unique(data$lang)
data <- data %>% filter(lang == "fr")
write.csv2(data,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv",
fileEncoding = "UTF-8")
View(data[8,])
data <- select(data,-c("profession"))
write.csv2(data,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv",
fileEncoding = "UTF-8")
names(data)
data_text <- data[,c("text","possibly_sensitive","created_at","twitter.x","sexe",
"twi_actif")]
data_text <- data[,c("text","possibly_sensitive","created_at","twitter.x","sexe")]
write.csv2(data,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv",
fileEncoding = "UTF-8")
write.csv2(data_text,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\sample_rem_del_cols.csv",
fileEncoding = "UTF-8")
data_text$created_at <- as.Date(data_text$created_at)
write.csv2(data_text,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv",
fileEncoding = "UTF-8")
View(data_text[8,])
data_text[8,1]
data_text[11,1]
data_text[10,1]
data_tweet <- data_text$text
data_tweet <- data_text[,"text"]
data_tweet <- as.data.frame(data_text[,"text"])
View(data_tweet)
rm(data_tweet)
write.csv(data_text,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv")
write.txt(data_text,data_text,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.txt")
write(data_text,data_text,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.txt")
write.csv(data_text,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv",
fileEncoding = "utf-8")
library("plyr")
library("dplyr")
library("data.table")
library("tidyverse")
data_text <- readRDS("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv")
data_text <- read_csv("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv")
library("plyr")
library("dplyr")
library("data.table")
library("tidyverse")
data_text <- read_csv("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv")
View(data_text)
data_text <- read.csv("C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv")
View(data_text)
data_text$created_at <- as.Date(data_text$created_at)
data_text$year <- year(data_text$created_at)
unique(data_text$year)
write.csv(data_text,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_text.csv",
fileEncoding = "utf-8")
data_2019_2020 <- data %>% filter(2018 < year < 2021)
data_2019_2020 <- data %>% filter(year in c("2019,2020"))
data_2019_2020 <- data %>% filter(year %in% c("2019,2020"))
data_2019_2020 <- data_text %>% filter(year %in% c("2019,2020"))
unique(data_2019_2020)
unique(data_2019_2020$year)
data_2019_2020 <- data_text %>% filter(year %in% c("2019","2020"))
unique(data_2019_2020$year)
write.csv(data_2019_2020,"C:\\Users\\HP\\Documents\\cours_ensae\\3A\\MLNLP\\Project\\data_2019_2020.csv",
fileEncoding = "utf-8")
#-----------------------------------------------------#
#
#     Project in Data Science for Social Sciences
#       Vague-specific regressions
#
#                               Chloe Lavest & Yasmine Houri
#                               Academic year 2021-2022
#
#-----------------------------------------------------#
cwd <- getwd()
setwd(gsub("Code","",cwd))
#-----------------------------------------------------#
source("Code/3_pre_processing_for_regs.R")
rm(wave1_test, wave5)
cwd <- getwd()
setwd(gsub("Code","",cwd))
source("Code/3_pre_processing_for_regs.R")
getwd()
cwd <- getwd()
getwd()
getSrcDirectory()[1]
rstudioapi::getActiveDocumentContext()$path
library(rstudioapi)
rstudioapi::getActiveDocumentContext()$path
getActiveDocumentContext()
dirname(parent.frame(2)$ofile)
source('C:/Users/HP/Project_DSSS/Code/0_settings.R', echo=TRUE)
getwd()
source('C:/Users/HP/Project_DSSS/Code/1_data_preprocessing.R', echo=TRUE)
source('C:/Users/HP/Project_DSSS/Code/0_settings.R', echo=TRUE)
source('C:/Users/HP/Project_DSSS/Code/0_settings.R', echo=TRUE)
cwd <- getwd()
setwd(paste0(cwd,"Project_DSSS"))
setwd(paste0(cwd,"/Project_DSSS"))
path <- "Data"
source('C:/Users/HP/Project_DSSS/Code/0_settings.R', echo=TRUE)
source('C:/Users/HP/Project_DSSS/Code/0_settings.R', echo=TRUE)
getwd()
dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd(gsub("Code","",getwd()))
getwd()
